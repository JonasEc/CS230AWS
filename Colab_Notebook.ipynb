{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NYwQ14afur7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys, os, pickle, time\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (Input, Flatten, Dense, Conv2D, MaxPool2D,\n",
        "                                GlobalAveragePooling2D, Activation, BatchNormalization,\n",
        "                                Dropout, GRU, Bidirectional, Reshape, Lambda)\n",
        "from tensorflow.keras import backend as K\n",
        "import sys, os, pickle, time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ChPo7H5Ckw",
        "colab_type": "code",
        "outputId": "1461707b-22c6-440a-8ade-5de4cc971917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/marcelosena/cs230\n",
        "!unzip cs230/CS230OCR/ProcessedData/KerasReady0.zip -d cs230/CS230OCR/ProcessedData/\n",
        "sys.path.append('/content/cs230/CS230OCR/NeuralNet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs230'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 73 (delta 15), reused 58 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "Archive:  cs230/CS230OCR/ProcessedData/KerasReady0.zip\n",
            "  inflating: cs230/CS230OCR/ProcessedData/KerasReady0.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP_bbeRBDOG-",
        "colab_type": "code",
        "outputId": "18eec1b5-ad87-442a-a5e4-abb9cd4c3e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = '/content/cs230/CS230OCR/'\n",
        "from utils.inputFinland import loadImgsWithLabels, DataGen\n",
        "from utils.BasicConfig import (BATCH_SIZE, FULLCHARDICT,  INPUTSHAPE, LOGDIR, SAVEDIR)\n",
        "from utils.Callbacks import VizCallback\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "  print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBr4ZS_3C1uI",
        "colab_type": "text"
      },
      "source": [
        "Downloading the large keras dataset through google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxenOGIDgzsZ",
        "colab_type": "code",
        "outputId": "ed9eaae1-0743-4437-ea5e-ee4929f2e103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGvZGUZwg_9M",
        "colab_type": "code",
        "outputId": "4d0dd220-384c-4d7e-e799-b790bedce2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip 'gdrive/My Drive/CS230/Keras_largeData/KerasReadyFull0.zip' -d cs230/CS230OCR/ProcessedData/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/My Drive/CS230/Keras_largeData/KerasReadyFull0.zip\n",
            "  inflating: cs230/CS230OCR/ProcessedData/KerasReadyFull0.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvN7s6Y841vT",
        "colab_type": "text"
      },
      "source": [
        "Data Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5y7VGW55jud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMGWIDTH = 128\n",
        "IMGHEIGHT = 64\n",
        "CHANNELS = 1\n",
        "INPUTSHAPE =  [IMGWIDTH,IMGHEIGHT,1]\n",
        "FULLCHARDICT = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'/':10,',':11, '+': 12, '-': 13, ' ': 14}\n",
        "CHARDICT = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'/':10,',':11, '+': 12, '-': 13,}\n",
        "INVDICT = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '/', 11: ',', 12: '+', 13: '-'}\n",
        "DICTLENGTH = len(CHARDICT) + 1 # for the empty string\n",
        "MAXCHARLENGTH = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2v2iX5ddyRR",
        "colab_type": "text"
      },
      "source": [
        "Preparing Finish Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuQKKtnj43wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y_label, Y_len,  N = loadImgsWithLabels(True)\n",
        "randomOrder = pickle.load(open(path + f'ProcessedData/orderFull.p', 'rb'))\n",
        "X = X[randomOrder]\n",
        "Y_label = Y_label[randomOrder]\n",
        "Y_len = Y_len[randomOrder]\n",
        "\n",
        "trainID = int(np.ceil(N*0.33))\n",
        "devID = trainID + int(np.ceil((N - trainID)/2))\n",
        "\n",
        "X_train = X[:trainID]\n",
        "Y_label_train = Y_label[:trainID]\n",
        "Y_len_train = Y_len[:trainID]\n",
        "\n",
        "X_dev = X[trainID:devID]\n",
        "Y_label_dev = Y_label[trainID:devID]\n",
        "Y_len_dev = Y_len[trainID:devID]\n",
        "\n",
        "X_test = X[devID:]\n",
        "Y_label_test = Y_label[devID:]\n",
        "Y_len_test = Y_len[devID:]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_label_train)).batch(BATCH_SIZE)\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((X_dev, Y_label_dev)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_label_test)).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NAQSLeJZND",
        "colab_type": "text"
      },
      "source": [
        "Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1HwKg3VKmlp",
        "colab_type": "code",
        "outputId": "b6f4601b-f930-44c9-a96e-3ea6e27ef00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "indexShow = 834\n",
        "plt.imshow(X_test[indexShow,:,:,0].T, cmap='Greys')\n",
        "plt.show()\n",
        "print(Y_label_test[indexShow])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[13. -1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_hDQUD_6twh",
        "colab_type": "text"
      },
      "source": [
        "Transfer Models Specifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGRcX9uct3PG",
        "colab_type": "code",
        "outputId": "608da11f-5c93-4bb9-9955-cae458e2bb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "INPUTSHAPE_CHAN3 =  [IMGWIDTH,IMGHEIGHT,3]\n",
        "X_train_CHAN3 = np.repeat(X_train, 3, -1)\n",
        "\n",
        "print(\"###########################\")\n",
        "print(\"########## VGG19 ##########\")\n",
        "print(\"###########################\")\n",
        "\n",
        "base_model_vgg = keras.applications.VGG19(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape= INPUTSHAPE_CHAN3,\n",
        "    include_top=False)\n",
        "base_model_vgg.trainable = False\n",
        "base_model_vgg.summary()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"############################\")\n",
        "print(\"######### ResNet50 #########\")\n",
        "print(\"############################\")\n",
        "\n",
        "base_model_resNet = keras.applications.ResNet50(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape= INPUTSHAPE_CHAN3,\n",
        "    include_top=False)\n",
        "base_model_resNet.trainable = False\n",
        "base_model_resNet.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###########################\n",
            "########## VGG19 ##########\n",
            "###########################\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 64, 3)]      0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 8, 256)        0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 8, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "############################\n",
            "######### ResNet50 #########\n",
            "############################\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 64, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 134, 70, 3)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 64, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 64, 32, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 64, 32, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 66, 34, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 32, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 32, 16, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 32, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 32, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 32, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 32, 16, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 32, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 32, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 32, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 32, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 32, 16, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 32, 16, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 32, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 32, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 32, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 32, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 32, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 32, 16, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 32, 16, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 32, 16, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 32, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 32, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 32, 16, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 32, 16, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 16, 8, 128)   32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 16, 8, 128)   0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 16, 8, 128)   147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 16, 8, 128)   0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 16, 8, 512)   131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 16, 8, 512)   66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 16, 8, 512)   2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 16, 8, 512)   2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 16, 8, 512)   0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 16, 8, 512)   0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 16, 8, 128)   65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 16, 8, 128)   0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 16, 8, 128)   147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 16, 8, 128)   0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 16, 8, 512)   66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 16, 8, 512)   2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 16, 8, 512)   0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 16, 8, 512)   0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 16, 8, 128)   65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 16, 8, 128)   0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 16, 8, 128)   147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 16, 8, 128)   0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 16, 8, 512)   66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 16, 8, 512)   2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 16, 8, 512)   0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 16, 8, 512)   0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 16, 8, 128)   65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 16, 8, 128)   0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 8, 128)   147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 8, 128)   512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 8, 128)   0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 8, 512)   66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 16, 8, 512)   2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 16, 8, 512)   0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 16, 8, 512)   0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 8, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 8, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 8, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 8, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 8, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 8, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 8, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 8, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 8, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 8, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 8, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 8, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 8, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 8, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 8, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 8, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 8, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 8, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 8, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 4, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 4, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 4, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 4, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 4, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 4, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 4, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 4, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 4, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 4, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 4, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 4, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 4, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 4, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 4, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 4, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 4, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bARsbqXIkKw",
        "colab_type": "text"
      },
      "source": [
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVW_NwKIIhLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JZH-ezsJx7t",
        "colab_type": "text"
      },
      "source": [
        "Keras Model Specifiation - Transfer Learning from VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7sW_59_w7pk",
        "colab_type": "code",
        "outputId": "aa9aae8b-4d91-4e59-c8c4-70bae8caeb59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Layer params:   Filts K  Padding  Name\n",
        "layer_params = [ [  64, 7, 'same',  'conv1'],\n",
        "                 [  64, 5, 'same',  'conv2'],\n",
        "                 [ 128, 3, 'same',  'conv3'],\n",
        "                 [ 128, 3, 'same',  'conv4'],\n",
        "                 [ 256, 3, 'same',  'conv5'],\n",
        "                 [ 256, 3, 'same',  'conv6'],\n",
        "                 ]\n",
        "wherePool = [1,3,5]\n",
        "\n",
        "# Network parameters\n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2,2)\n",
        "denseSize = 128\n",
        "rnn_size = 256\n",
        "act = 'relu'\n",
        "minibatch_size = BATCH_SIZE\n",
        "retrain = False\n",
        "\n",
        "### Transfer-Learned Conv-NN ###\n",
        "tiling = [1] * 4\n",
        "tiling[-1] *= 3\n",
        "inputs = Input(name='the_input', shape=INPUTSHAPE)\n",
        "inner = keras.backend.tile(inputs, tiling)\n",
        "\n",
        "# inner = base_model(inner)\n",
        "base_model = base_model_vgg\n",
        "\n",
        "# # full model\n",
        "# inner = base_model(inner, training=False)\n",
        "\n",
        "# # only the first conv-nn part\n",
        "# l1 = base_model.layers[0]\n",
        "# l2 = base_model.layers[1]\n",
        "# l3 = base_model.layers[2]\n",
        "# l4 = base_model.layers[3]\n",
        "# l5 = base_model.layers[4]\n",
        "# l1.set_weights = l1.get_weights()\n",
        "# l2.set_weights = l2.get_weights()\n",
        "# l3.set_weights = l3.get_weights()\n",
        "# l4.set_weights = l4.get_weights()\n",
        "# l5.set_weights = l5.get_weights()\n",
        "\n",
        "# # # Setting layers to non-trainable\n",
        "# l1.trainable = retrain\n",
        "# l2.trainable = retrain\n",
        "# l3.trainable = retrain\n",
        "# l4.trainable = retrain\n",
        "# l5.trainable = retrain\n",
        "# inner = l1(inner)\n",
        "# inner = l2(inner)\n",
        "# inner = l3(inner)\n",
        "# inner = l4(inner)\n",
        "# inner = l5(inner)\n",
        "\n",
        "print(len(base_model.layers))\n",
        "### all conv-nn parts\n",
        "for ll in range(len(base_model.layers) - 7):\n",
        "  # if ll != 14 and ll != 17 and ll != 27 and ll != 37 and ll != 45 and ll != 49 and ll != 59 and ll != 69 and ll != 79 and ll != 87 and ll != 91 and ll != 101 and ll != 111:\n",
        "    tmp_ll = base_model.layers[ll]\n",
        "    tmp_ll.set_weights = base_model.layers[ll].get_weights()\n",
        "    tmp_ll.trainable = retrain\n",
        "    inner = tmp_ll(inner)\n",
        "\n",
        "# ### Our Conv-NN ###\n",
        "# inputs = Input(name='the_input', shape=INPUTSHAPE)\n",
        "# layer = layer_params[0]\n",
        "# inner = Conv2D(layer[0], layer[1], strides=(1,1), padding=layer[2], activation=act,\n",
        "#                      use_bias=False, kernel_initializer=\"he_normal\", name=layer[3] )(inputs)\n",
        "# inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "# for i in range(1,len(layer_params)):\n",
        "#     layer = layer_params[i]\n",
        "#     inner = Conv2D(layer[0], layer[1], strides=(1,1), padding=layer[2], activation=act,\n",
        "#                      use_bias=False, kernel_initializer=\"he_normal\", name=layer[3] )(inner)\n",
        "#     inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "#     if i in wherePool:\n",
        "#        inner = MaxPool2D(pool_size=pool_size, strides=(2, 2), padding='same', name=f'pool{i+1}')(inner)\n",
        "\n",
        "# conv_to_rnn_dims = ( IMGWIDTH// (pool_size[0] ** len(wherePool)) ,\n",
        "#                     (IMGHEIGHT  // (pool_size[0] ** len(wherePool))) * layer_params[-1][0]\n",
        "#                    )\n",
        "# print(conv_to_rnn_dims)\n",
        "\n",
        "inner = inner\n",
        "trOutShape = inner.shape\n",
        "conv_to_rnn_dims_transfer = (trOutShape[1], trOutShape[2]*trOutShape[3])\n",
        "# print(trOutShape)\n",
        "# print(conv_to_rnn_dims_transfer)\n",
        "\n",
        "inner = Reshape(target_shape=conv_to_rnn_dims_transfer, name='reshape')(inner)\n",
        "inner = Dense(denseSize, activation=act, name='dense1')(inner)\n",
        "inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "# # Two layers of bidirectional GRUs\n",
        "gru_1 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru1'), merge_mode='sum')(inner)\n",
        "gru_2 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru2'))(gru_1)\n",
        "y_pred = Dense(DICTLENGTH, kernel_initializer='he_normal', name='densePredict', activation='softmax')(gru_2)\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "# keras.Model(inputs=inputs, outputs=y_pred).summary()\n",
        "\n",
        "#%%\n",
        "labels = Input(name='the_labels', shape=[MAXCHARLENGTH], dtype='float32')\n",
        "input_length = Input(name='input_length',\n",
        "                     shape=[1], #IMGWIDTH// (pool_size[0] ** len(wherePool)) - 2\n",
        "                     dtype='int64')\n",
        "label_length = Input(name='label_length',\n",
        "                     shape=[1],\n",
        "                     dtype='int64')\n",
        "print(label_length)\n",
        "\n",
        "#CTC loss is implemented in a lambda layer\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,),\n",
        "    name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.02,\n",
        "          decay=1e-6,\n",
        "          momentum=0.9,\n",
        "          nesterov=True)\n",
        "model = keras.Model(inputs=[inputs, labels, input_length, label_length],\n",
        "              outputs=loss_out)\n",
        "\n",
        "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "# test_func = K.function([inputs], [y_pred])\n",
        "# model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Tensor(\"densePredict/Identity:0\", shape=(None, 16, 15), dtype=float32)\n",
            "(None, 16, 15)\n",
            "Tensor(\"label_length:0\", shape=(None, 1), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIdQ0r_-8Z3R",
        "colab_type": "text"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDmsPM-j8KVS",
        "colab_type": "code",
        "outputId": "dcf0268f-d360-4c5f-81ed-76d919682111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generatorTrain = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_train, Y_label_train, Y_len_train,  len(X_train), 0)\n",
        "generatorVal = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_dev, Y_label_dev, Y_len_dev,  len(X_dev), 0)\n",
        "generatorTest = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_test, Y_label_test, Y_len_test,  len(X_test), 0)\n",
        "\n",
        "#viz_cb = VizCallback(run_name, test_func, generatorVal.get_batch())\n",
        "# early_stopping= keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='acc', baseline = 0.95, min_delta = 0.1, restore_best_weights=True)\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"bestRunning_model.hdf5\",\n",
        "                                            monitor='loss', verbose=1,\n",
        "                                            save_best_only=True, mode='auto')\n",
        "\n",
        "#%%\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "usualCallback = EarlyStopping()\n",
        "callCheck = [usualCallback, checkpoint]\n",
        "\n",
        "history = model.fit(generatorTrain.get_batch(), epochs=5,\n",
        "                       validation_data = generatorVal.get_batch(),\n",
        "                    validation_steps = len(X_dev)//BATCH_SIZE,\n",
        "                    steps_per_epoch = 20) #,\n",
        "                    # callbacks = [usualCallback])\n",
        "                    #callbacks=[viz_cb, early_stopping, checkpoint],)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 18s 904ms/step - loss: 7.2382 - accuracy: 0.3375 - val_loss: 6.7142 - val_accuracy: 0.1850\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 17s 837ms/step - loss: 3.8312 - accuracy: 0.4656 - val_loss: 4.7698 - val_accuracy: 0.3292\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 16s 815ms/step - loss: 2.8068 - accuracy: 0.5906 - val_loss: 2.8508 - val_accuracy: 0.6784\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 16s 805ms/step - loss: 2.8688 - accuracy: 0.5609 - val_loss: 2.6560 - val_accuracy: 0.6813\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 17s 844ms/step - loss: 2.2756 - accuracy: 0.6453 - val_loss: 2.3548 - val_accuracy: 0.7046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA4UAcxgcI3M",
        "colab_type": "text"
      },
      "source": [
        "Keras Model Specifiation - Transfer Learning from ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUjqZJfqZxV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5053cb2e-c50b-4ed9-ebe9-bd4095595bce"
      },
      "source": [
        "# Network parameters\n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2,2)\n",
        "denseSize = 128\n",
        "rnn_size = 256\n",
        "act = 'relu'\n",
        "minibatch_size = BATCH_SIZE\n",
        "retrain = False\n",
        "\n",
        "### Transfer-Learned Conv-NN ###\n",
        "tiling = [1] * 4\n",
        "tiling[-1] *= 3\n",
        "inputs = Input(name='the_input', shape=INPUTSHAPE)\n",
        "inner = keras.backend.tile(inputs, tiling)\n",
        "\n",
        "# inner = base_model(inner)\n",
        "base_model = base_model_resNet\n",
        "\n",
        "print(len(base_model.layers))\n",
        "### all conv-nn parts\n",
        "for ll in range(len(base_model.layers) - 120):\n",
        "  if ll != 14 and ll != 17 and ll != 27 and ll != 37 and ll != 45 and ll != 49 and ll != 59 and ll != 69 and ll != 79 and ll != 87 and ll != 91 and ll != 101 and ll != 111:\n",
        "    tmp_ll = base_model.layers[ll]\n",
        "    tmp_ll.set_weights = base_model.layers[ll].get_weights()\n",
        "    tmp_ll.trainable = retrain\n",
        "    inner = tmp_ll(inner)\n",
        "\n",
        "inner = inner\n",
        "trOutShape = inner.shape\n",
        "conv_to_rnn_dims_transfer = (trOutShape[1], trOutShape[2]*trOutShape[3])\n",
        "inner = Reshape(target_shape=conv_to_rnn_dims_transfer, name='reshape')(inner)\n",
        "inner = Dense(denseSize, activation=act, name='dense1')(inner)\n",
        "inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "# # Two layers of bidirectional GRUs\n",
        "gru_1 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru1'), merge_mode='sum')(inner)\n",
        "gru_2 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru2'))(gru_1)\n",
        "y_pred = Dense(DICTLENGTH, kernel_initializer='he_normal', name='densePredict', activation='softmax')(gru_2)\n",
        "\n",
        "#%%\n",
        "labels = Input(name='the_labels', shape=[MAXCHARLENGTH], dtype='float32')\n",
        "input_length = Input(name='input_length',\n",
        "                     shape=[1], #IMGWIDTH// (pool_size[0] ** len(wherePool)) - 2\n",
        "                     dtype='int64')\n",
        "label_length = Input(name='label_length',\n",
        "                     shape=[1],\n",
        "                     dtype='int64')\n",
        "\n",
        "#CTC loss is implemented in a lambda layer\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,),\n",
        "    name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.02,\n",
        "          decay=1e-6,\n",
        "          momentum=0.9,\n",
        "          nesterov=True)\n",
        "model = keras.Model(inputs=[inputs, labels, input_length, label_length],\n",
        "              outputs=loss_out)\n",
        "\n",
        "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "## Fitting\n",
        "generatorTrain = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_train, Y_label_train, Y_len_train,  len(X_train), 0)\n",
        "generatorVal = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_dev, Y_label_dev, Y_len_dev,  len(X_dev), 0)\n",
        "generatorTest = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_test, Y_label_test, Y_len_test,  len(X_test), 0)\n",
        "\n",
        "#viz_cb = VizCallback(run_name, test_func, generatorVal.get_batch())\n",
        "# early_stopping= keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='acc', baseline = 0.95, min_delta = 0.001, restore_best_weights=True)\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"bestRunning_model.hdf5\",\n",
        "                                            monitor='loss', verbose=1,\n",
        "                                            save_best_only=True, mode='auto')\n",
        "\n",
        "#%%\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "usualCallback = EarlyStopping()\n",
        "callCheck = [usualCallback, checkpoint]\n",
        "\n",
        "history = model.fit(generatorTrain.get_batch(), epochs=1,\n",
        "                       validation_data = generatorVal.get_batch(),\n",
        "                    validation_steps = len(X_dev)//BATCH_SIZE,\n",
        "                    steps_per_epoch = 20) #,\n",
        "                    # callbacks = [usualCallback])\n",
        "                    #callbacks=[viz_cb, early_stopping, checkpoint],)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "20/20 [==============================] - 15s 751ms/step - loss: 10.6639 - accuracy: 0.3422 - val_loss: 8.3044 - val_accuracy: 0.6944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UxLJ4XWduAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}